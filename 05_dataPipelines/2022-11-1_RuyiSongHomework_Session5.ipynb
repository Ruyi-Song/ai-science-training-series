{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1667317374437,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "bKgNn93CS9LC"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time,math\n",
    "\n",
    "# This limits the amount of memory used:\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2\"\n",
    "# This control parallelism in Tensorflow\n",
    "parallel_threads = 128\n",
    "# This controls how many batches to prefetch\n",
    "prefetch_buffer_size = 8 # tf.data.AUTOTUNE\n",
    "os.environ['OMP_NUM_THREADS'] = str(parallel_threads)\n",
    "num_parallel_readers = parallel_threads\n",
    "\n",
    "# how many training steps to take during profiling\n",
    "num_steps = 10\n",
    "use_profiler = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6461,
     "status": "ok",
     "timestamp": 1667317383838,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "CAwIzoBIS27b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.profiler import trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1667317395808,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "VNf6J6_lThao"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Here's the Residual layer from the first half again:\n",
    "#########################################################################\n",
    "class ResidualLayer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, n_filters):\n",
    "        # tf.keras.Model.__init__(self)\n",
    "        super(ResidualLayer, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters     = n_filters,\n",
    "            kernel_size = (3,3),\n",
    "            padding     = \"same\"\n",
    "        )\n",
    "\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters     = n_filters,\n",
    "            kernel_size = (3,3),\n",
    "            padding     = \"same\"\n",
    "        )\n",
    "\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = inputs\n",
    "\n",
    "        output1 = self.norm1(self.conv1(inputs))\n",
    "\n",
    "        output1 = tf.keras.activations.relu(output1)\n",
    "\n",
    "        output2 = self.norm2(self.conv2(output1))\n",
    "\n",
    "        return tf.keras.activations.relu(output2 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1667317398364,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "lYtH9xxyThyH"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Here's layer that does a spatial downsampling:\n",
    "#########################################################################\n",
    "class ResidualDownsample(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, n_filters):\n",
    "        # tf.keras.Model.__init__(self)\n",
    "        super(ResidualDownsample, self).__init__()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters     = n_filters,\n",
    "            kernel_size = (3,3),\n",
    "            padding     = \"same\",\n",
    "            strides     = (2,2)\n",
    "        )\n",
    "\n",
    "        self.identity = tf.keras.layers.Conv2D(\n",
    "            filters     = n_filters,\n",
    "            kernel_size = (1,1),\n",
    "            strides     = (2,2),\n",
    "            padding     = \"same\"\n",
    "        )\n",
    "\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters     = n_filters,\n",
    "            kernel_size = (3,3),\n",
    "            padding     = \"same\"\n",
    "        )\n",
    "\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.identity(inputs)\n",
    "        output1 = self.norm1(self.conv1(inputs))\n",
    "        output1 = tf.keras.activations.relu(output1)\n",
    "\n",
    "        output2 = self.norm2(self.conv2(output1))\n",
    "\n",
    "        return tf.keras.activations.relu(output2 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1667317403368,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "H5xD93rCVVyi"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Armed with that, let's build ResNet (this particular one is called ResNet34)\n",
    "#########################################################################\n",
    "\n",
    "class ResNet34(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNet34, self).__init__()\n",
    "\n",
    "        self.conv_init = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters     = 64,\n",
    "                kernel_size = (7,7),\n",
    "                strides     = (2,2),\n",
    "                padding     = \"same\",\n",
    "                use_bias    = False\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding=\"same\")\n",
    "\n",
    "        ])\n",
    "\n",
    "        self.residual_series_1 = tf.keras.Sequential([\n",
    "            ResidualLayer(64),\n",
    "            ResidualLayer(64),\n",
    "            ResidualLayer(64),\n",
    "        ])\n",
    "\n",
    "        # Increase the number of filters:\n",
    "        self.downsample_1 = ResidualDownsample(128)\n",
    "\n",
    "        self.residual_series_2 = tf.keras.Sequential([\n",
    "            ResidualLayer(128),\n",
    "            ResidualLayer(128),\n",
    "            ResidualLayer(128),\n",
    "        ])\n",
    "\n",
    "        # Increase the number of filters:\n",
    "        self.downsample_2 = ResidualDownsample(256)\n",
    "\n",
    "        self.residual_series_3 = tf.keras.Sequential([\n",
    "            ResidualLayer(256),\n",
    "            ResidualLayer(256),\n",
    "            ResidualLayer(256),\n",
    "            ResidualLayer(256),\n",
    "            ResidualLayer(256),\n",
    "        ])\n",
    "\n",
    "        # Increase the number of filters:\n",
    "        self.downsample_3 = ResidualDownsample(512)\n",
    "\n",
    "\n",
    "        self.residual_series_4 = tf.keras.Sequential([\n",
    "            ResidualLayer(512),\n",
    "            ResidualLayer(512),\n",
    "        ])\n",
    "\n",
    "        self.final_pool = tf.keras.layers.AveragePooling2D(\n",
    "            pool_size=(8,8)\n",
    "        )\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.classifier = tf.keras.layers.Dense(1000)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv_init(inputs)\n",
    "\n",
    "        x = self.residual_series_1(x)\n",
    "\n",
    "\n",
    "        x = self.downsample_1(x)\n",
    "\n",
    "\n",
    "        x = self.residual_series_2(x)\n",
    "\n",
    "        x = self.downsample_2(x)\n",
    "\n",
    "        x = self.residual_series_3(x)\n",
    "\n",
    "        x = self.downsample_3(x)\n",
    "\n",
    "\n",
    "        x = self.residual_series_4(x)\n",
    "\n",
    "\n",
    "        x = self.final_pool(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667317407238,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "QXFdDuptVr8k"
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def calculate_accuracy(logits, labels):\n",
    "    # We calculate top1 accuracy only here:\n",
    "    selected_class = tf.argmax(logits, axis=1)\n",
    "\n",
    "    correct = tf.cast(selected_class, tf.float32) == tf.cast(labels, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def calculate_loss(logits, labels):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1667317410348,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "8SeinLrAVxZV"
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_step(network, optimizer, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = network(images)\n",
    "        loss = calculate_loss(logits, labels)\n",
    "\n",
    "    gradients = tape.gradient(loss, network.trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, network.trainable_variables))\n",
    "\n",
    "    accuracy = calculate_accuracy(logits, labels)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "@trace.trace_wrapper('train_epoch')\n",
    "def train_epoch(i_epoch, step_in_epoch, train_ds, val_ds, network, optimizer, BATCH_SIZE, checkpoint):\n",
    "    # Here is our training loop!\n",
    "\n",
    "    steps_per_epoch = int(1281167 / BATCH_SIZE)\n",
    "    steps_validation = int(50000 / BATCH_SIZE)\n",
    "\n",
    "    # added for profiling\n",
    "    if use_profiler:\n",
    "        print('start profiler')\n",
    "        tf.profiler.experimental.start('logdir/m%03d_w%02d_p%02d' % (parallel_threads,num_parallel_readers,prefetch_buffer_size))\n",
    "    \n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    sum = 0.\n",
    "    sum2 = 0.\n",
    "    for train_images, train_labels in train_ds.take(steps_per_epoch):\n",
    "        if step_in_epoch > steps_per_epoch: break\n",
    "        else: step_in_epoch.assign_add(1)\n",
    "\n",
    "        # Peform the training step for this batch\n",
    "        loss, acc = training_step(network, optimizer, train_images, train_labels)\n",
    "        end = time.time()\n",
    "        images_per_second = BATCH_SIZE / (end - start)\n",
    "        if i > 0: # skip the first measurement because it includes compile time\n",
    "            sum += images_per_second\n",
    "            sum2 += images_per_second * images_per_second\n",
    "        print(f\"Finished step {step_in_epoch.numpy()} of {steps_per_epoch} in epoch {i_epoch.numpy()},loss={loss:.3f}, acc={acc:.3f} ({images_per_second:.3f} img/s).\")\n",
    "        start = time.time()\n",
    "        # added for profiling to stop after some steps\n",
    "        i += 1\n",
    "        if i > num_steps and use_profiler: break\n",
    "    \n",
    "    # added for profiling to stop after some steps\n",
    "    if use_profiler:\n",
    "        print('stop profiler')\n",
    "        i = i - 1\n",
    "        mean_rate = sum / i\n",
    "        stddev_rate = math.sqrt( sum2/i - mean_rate * mean_rate )\n",
    "        print(f'mean image/s = {mean_rate:8.2f}   standard deviation: {stddev_rate:8.2f}')\n",
    "        tf.profiler.experimental.stop()\n",
    "        sys.exit(0)\n",
    "\n",
    "    # Save the network after every epoch:\n",
    "    checkpoint.save(\"resnet34/model\")\n",
    "    \n",
    "    # Compute the validation accuracy:\n",
    "    mean_accuracy = None\n",
    "    for val_images, val_labels in val_ds.take(steps_validation):\n",
    "        logits = network(val_images)\n",
    "        accuracy = calculate_accuracy(logits, val_labels)\n",
    "        if mean_accuracy is None:\n",
    "            mean_accuracy = accuracy\n",
    "        else:\n",
    "            mean_accuracy += accuracy\n",
    "\n",
    "    mean_accuracy /= steps_validation\n",
    "\n",
    "    print(f\"Validation accuracy after epoch {i_epoch.numpy()}: {mean_accuracy:.4f}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1667317414403,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "3iegwFwMVxsr"
   },
   "outputs": [],
   "source": [
    "# @trace.trace_wrapper('prepare_data_loader')\n",
    "def prepare_data_loader(BATCH_SIZE):\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(parallel_threads)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(parallel_threads)\n",
    "    print('threading set: ',tf.config.threading.get_inter_op_parallelism_threads(),tf.config.threading.get_intra_op_parallelism_threads())\n",
    "\n",
    "    print(\"Parameters set, preparing dataloading\")\n",
    "    #########################################################################\n",
    "    # Here's the part where we load datasets:\n",
    "    import json\n",
    "\n",
    "\n",
    "    # What's in this function?  Tune in next week ...\n",
    "    from ilsvrc_dataset import get_datasets\n",
    "\n",
    "\n",
    "    class FakeHvd:\n",
    "\n",
    "        def size(self): return 1\n",
    "\n",
    "        def rank(self): return 0\n",
    "\n",
    "\n",
    "    with open(\"ilsvrc.json\", 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    config['data']['batch_size'] = BATCH_SIZE\n",
    "    config['data']['num_parallel_readers'] = num_parallel_readers\n",
    "    config['data']['prefetch_buffer_size'] = prefetch_buffer_size \n",
    "\n",
    "    print(json.dumps(config, indent=4))\n",
    "\n",
    "    config['hvd'] = FakeHvd()\n",
    "\n",
    "    train_ds, val_ds = get_datasets(config)\n",
    "\n",
    "    options = tf.data.Options()\n",
    "    options.threading.private_threadpool_size = parallel_threads\n",
    "    train_ds = train_ds.with_options(options)\n",
    "    val_ds = val_ds.with_options(options)\n",
    "\n",
    "    print(\"Datasets ready, creating network.\")\n",
    "    #########################################################################\n",
    "\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "error",
     "timestamp": 1667317422531,
     "user": {
      "displayName": "宋汝怿",
      "userId": "14175445932911205844"
     },
     "user_tz": 240
    },
    "id": "mEF-PKMOWy2l",
    "outputId": "1fd14254-4de3-4047-f774-a268fe9e143f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threading set:  128 128\n",
      "Parameters set, preparing dataloading\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d68814921bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d68814921bc0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d0c55adbfc39>\u001b[0m in \u001b[0;36mprepare_data_loader\u001b[0;34m(BATCH_SIZE)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# What's in this function?  Tune in next week ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0milsvrc_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ilsvrc_dataset'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #########################################################################\n",
    "    # Here's some configuration:\n",
    "    #########################################################################\n",
    "    BATCH_SIZE = 256\n",
    "    N_EPOCHS = 10\n",
    "\n",
    "    train_ds, val_ds = prepare_data_loader(BATCH_SIZE)\n",
    "\n",
    "\n",
    "    example_images, example_labels = next(iter(train_ds.take(1)))\n",
    "\n",
    "\n",
    "    print(\"Initial Image size: \", example_images.shape)\n",
    "    network = ResNet34()\n",
    "\n",
    "    output = network(example_images)\n",
    "    print(\"output shape:\", output.shape)\n",
    "\n",
    "    print(network.summary())\n",
    "\n",
    "    epoch = tf.Variable(initial_value=tf.constant(0, dtype=tf.dtypes.int64), name='epoch')\n",
    "    step_in_epoch = tf.Variable(\n",
    "        initial_value=tf.constant(0, dtype=tf.dtypes.int64),\n",
    "        name='step_in_epoch')\n",
    "\n",
    "\n",
    "    # We need an optimizer.  Let's use Adam:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(\n",
    "        network       = network,\n",
    "        optimizer     = optimizer,\n",
    "        epoch         = epoch,\n",
    "        step_in_epoch = step_in_epoch)\n",
    "\n",
    "    # Restore the model, if possible:\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(\"resnet34/\")\n",
    "    if latest_checkpoint:\n",
    "        checkpoint.restore(latest_checkpoint)\n",
    "\n",
    "    while epoch < N_EPOCHS:\n",
    "        train_epoch(epoch, step_in_epoch, train_ds, val_ds, network, optimizer, BATCH_SIZE, checkpoint)\n",
    "        epoch.assign_add(1)\n",
    "        step_in_epoch.assign(0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzARRfql5Gd06r8RsLPOpa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda/2022-07-01",
   "language": "python",
   "name": "conda-2022-07-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
